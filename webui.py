import json
import os
import io
import zipfile
import streamlit as st
import core_logic as core
import pandas as pd
import time
from sentence_transformers import SentenceTransformer

# è·å–å½“å‰è„šæœ¬æ‰€åœ¨çš„ç»å¯¹ç›®å½•
PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))
# æ‹¼æ¥å‡ºæ•°æ®åº“çš„é»˜è®¤è·¯å¾„ (ç»Ÿä¸€ä½¿ç”¨ subtitle_library.db)
DEFAULT_DB_PATH = os.path.join(PROJECT_ROOT, "subtitle_library.db")
# ==========================================
# ç¼“å­˜ä¸é¡µé¢åŸºç¡€
# ==========================================
@st.cache_data(ttl=60)
def cached_get_library_stats():
    return core.get_library_stats()

st.set_page_config(
    page_title="AI å­—å¹•ç‚¼é‡‘æœ¯å¸ˆ",
    page_icon="ğŸ¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==========================================
# æ¨¡å‹åŠ è½½å™¨ (ç¼“å­˜)
# ==========================================
@st.cache_resource(show_spinner="æ­£åœ¨åŠ è½½ AI æ¨¡å‹ï¼Œè¯·ç¨å€™...")
def load_embedding_model(model_name):
    try:
        print(f"ğŸ”„ Cache Miss: æ­£åœ¨åŠ è½½æ¨¡å‹ {model_name}...")
        return SentenceTransformer(model_name)
    except Exception as e:
        raise RuntimeError(f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")

# ==========================================
# ä¾§è¾¹æ ï¼šå…¨å±€æ§åˆ¶
# ==========================================
with st.sidebar:
    st.title("ğŸ›ï¸ æ§åˆ¶å°")
    CONFIG_FILE = "config.json"
    if 'config_loaded' not in st.session_state:
        if os.path.exists(CONFIG_FILE):
            # æƒ…å†µ 1ï¼šè€ç”¨æˆ·ï¼Œæœ‰é…ç½®æ–‡ä»¶ï¼ˆä½†å¯èƒ½ç¼ºå°‘ db_pathï¼‰
            with open(CONFIG_FILE, 'r') as f:
                st.session_state['config'] = json.load(f)
        else:
            # æƒ…å†µ 2ï¼šæ–°ç”¨æˆ·ï¼Œæ²¡æœ‰é…ç½®æ–‡ä»¶
            default_path = os.path.join(os.path.expanduser("~"), "Movies", "Subtitles")
            
            if not os.path.exists(default_path):
                try:
                    os.makedirs(default_path)
                except:
                    pass

            st.session_state['config'] = {
                'library_path': default_path,
                'embedding_model': "moka-ai/m3e-base",
                'db_path': DEFAULT_DB_PATH
            }

        # ğŸ”¥ã€å…³é”®ä¿®æ”¹ã€‘è¿™è¡Œä»£ç å¿…é¡»é¡¶æ ¼å†™ï¼ˆå’Œä¸Šé¢çš„ if/else å¯¹é½ï¼‰ï¼Œä¸è¦ç¼©è¿›ï¼
        # è¿™æ ·æ— è®ºæ˜¯æƒ…å†µ 1 è¿˜æ˜¯æƒ…å†µ 2ï¼Œæœ€åéƒ½ä¼šæ‰§è¡Œè¿™ä¸ªæ£€æŸ¥
        if 'db_path' not in st.session_state['config']:
            st.session_state['config']['db_path'] = DEFAULT_DB_PATH
        st.session_state['config_loaded'] = True

    def save_config():
        st.session_state['config']['library_path'] = st.session_state['path_input']
        with open(CONFIG_FILE, 'w') as f:
            json.dump(st.session_state['config'], f)
        st.toast("âœ… è·¯å¾„é…ç½®å·²ä¿å­˜")
        cached_get_library_stats.clear()

    library_path = st.text_input(
        "ğŸ“‚ å­—å¹•åº“æ ¹ç›®å½•",
        value=st.session_state['config']['library_path'],
        key="path_input",
        on_change=save_config
    )
    # --- è¯­ä¹‰æ¨¡å‹é€‰æ‹© ---
    model_options = {
        "paraphrase-multilingual-MiniLM-L12-v2": "ğŸš€ æé€Ÿç‰ˆ (MiniLM - æ¨è)",
        "moka-ai/m3e-base": "ğŸ‡¨ğŸ‡³ ä¸­æ–‡æ ‡å‡†ç‰ˆ (M3E - é»˜è®¤)",
        "BAAI/bge-m3": "ğŸ”¥ æ——èˆ°ç‰ˆ (BGE-M3 - è¾ƒæ…¢)",
        "custom": "ğŸ› ï¸ è‡ªå®šä¹‰ (æ‰‹åŠ¨è¾“å…¥æ¨¡å‹ID)"
    }
    current_config_model = st.session_state['config'].get('embedding_model', "moka-ai/m3e-base")
    if current_config_model in model_options:
        default_index = list(model_options.keys()).index(current_config_model)
        radio_key_value = current_config_model
    else:
        default_index = list(model_options.keys()).index("custom")
        radio_key_value = "custom"
    selected_option = st.selectbox(
        "ğŸ§  è¯­ä¹‰æ¨¡å‹ (Embedding)",
        options=list(model_options.keys()),
        format_func=lambda x: model_options[x],
        index=default_index,
        key="model_select_box",
        help="å†³å®šäº†AIå¦‚ä½•ç†è§£ä¸­æ–‡ã€‚å»ºè®®ä½¿ç”¨ M3Eã€‚"
    )
    if selected_option == "custom":
        custom_model_id = st.text_input(
            "è¾“å…¥ HuggingFace ID æˆ– æœ¬åœ°è·¯å¾„",
            value=current_config_model if radio_key_value == "custom" else "sentence-transformers/all-mpnet-base-v2",
            help="ä¾‹å¦‚ï¼šintfloat/multilingual-e5-large"
        )
        selected_model = custom_model_id.strip() if custom_model_id else "moka-ai/m3e-base"
    else:
        selected_model = selected_option
    if selected_model != current_config_model:
        st.divider()
        st.info(f"å‡†å¤‡åˆ‡æ¢ä¸ºï¼š{selected_model}")
        st.warning(
            "âš ï¸ æ¨¡å‹å·²å˜æ›´ï¼\n\nè¯·åŠ¡å¿…å»ã€Œæ•°æ®åº“ç®¡ç†ã€ç‚¹å‡»ã€Œé‡æ–°æ‰«æã€ï¼Œå¦åˆ™æ— æ³•ä½¿ç”¨æ–°æ¨¡å‹æœç´¢ï¼", 
            icon="ğŸš¨"
        )
    st.divider()
    st.toggle("ğŸ‰ å¯ç”¨å…¥åº“å½©è›‹", value=st.session_state.get("easter_egg", True), key="easter_egg")
    st.divider()
    # --- LLM å¤§æ¨¡å‹é…ç½®ï¼ˆæŠ˜å ï¼‰---
    with st.expander("ğŸ”‘ LLM å¤§æ¨¡å‹é…ç½® (å…¨å±€)", expanded=False):
        cfg = st.session_state['config']
        default_provider = cfg.get('llm_provider', "DeepSeek")
        default_key = cfg.get('llm_key', "")
        default_base = cfg.get('llm_base_url', "https://api.deepseek.com")
        provider = st.selectbox(
            "å‚å•†", 
            ["DeepSeek", "OpenAI", "Google", "Custom", "Local (Ollama)"],
            index=["DeepSeek", "OpenAI", "Google", "Custom", "Local (Ollama)"].index(default_provider) if default_provider in ["DeepSeek", "OpenAI", "Google", "Custom", "Local (Ollama)"] else 0,
            key="llm_provider"
        )
        api_key = st.text_input("API Key", value=default_key, type="password", key="llm_key_input", help="DeepSeek æˆ– OpenAI çš„ SK")
        model_presets = {
            "DeepSeek": ["deepseek-chat", "deepseek-reasoner"], # V3 å’Œ R1
            "OpenAI": ["gpt-4o", "gpt-4o-mini", "gpt-4-turbo"],
            "Google": ["gemini-1.5-pro", "gemini-1.5-flash"],
            "Local (Ollama)": ["llama3", "qwen2.5", "mistral"], # å¸¸ç”¨æœ¬åœ°æ¨¡å‹
            "Custom": []
        }
        current_model_val = cfg.get('llm_model_name', "")
        if provider in model_presets and model_presets[provider]:
            options = model_presets[provider] + ["âœï¸ æ‰‹åŠ¨è¾“å…¥..."]
            try:
                pre_index = options.index(current_model_val)
            except ValueError:
                pre_index = 0
            selected_preset = st.selectbox("æ¨¡å‹ç‰ˆæœ¬", options, index=pre_index, key="llm_model_select")
            
            if selected_preset == "âœï¸ æ‰‹åŠ¨è¾“å…¥...":
                model_name = st.text_input("è¯·è¾“å…¥æ¨¡å‹ ID", value=current_model_val, placeholder="ä¾‹å¦‚: deepseek-coder", key="llm_model_manual")
            else:
                model_name = selected_preset
        else:
            model_name = st.text_input("æ¨¡å‹åç§°", value=current_model_val, placeholder="å¦‚ llama3", key="llm_model_manual_only")
        placeholder_base = "https://api.deepseek.com"
        auto_fill_base = default_base
        
        if provider == "DeepSeek": 
            placeholder_base = "https://api.deepseek.com"
            if "openai" in default_base or "localhost" in default_base: auto_fill_base = placeholder_base
        elif provider == "OpenAI": 
            placeholder_base = "https://api.openai.com/v1"
            if "deepseek" in default_base: auto_fill_base = placeholder_base
        elif provider == "Local (Ollama)":
            placeholder_base = "http://localhost:11434/v1"
        base_url = st.text_input("Base URL", value=auto_fill_base, placeholder=placeholder_base, key="llm_base_input")
        if st.button("ğŸ’¾ ä¿å­˜é…ç½®", use_container_width=True):
            st.session_state['config']['llm_provider'] = provider
            st.session_state['config']['llm_key'] = api_key
            st.session_state['config']['llm_base_url'] = base_url
            st.session_state['config']['llm_model_name'] = model_name
            
            with open(CONFIG_FILE, 'w') as f:
                json.dump(st.session_state['config'], f)
            st.toast(f"âœ… å·²ä¿å­˜ï¼šä½¿ç”¨ {provider} - {model_name}")
            time.sleep(1)
            st.rerun()
        st.session_state['llm_config'] = {
            "provider": provider,
            "api_key": api_key,
            "base_url": base_url,
            "model_name": model_name
        }

# ==========================================
# ä¸»ç•Œé¢æ ‡é¢˜ä¸ Tab å¯¼èˆª
# ==========================================
st.title("ğŸ¬ AI å­—å¹•ç‚¼é‡‘æœ¯å¸ˆ")
st.markdown("Automated Subtitle Processing & AI Script Generation System")
tab1, tab2, tab3 = st.tabs(["ğŸ§¹ æ¸…æ´—ä¸è½¬ç ", "ğŸ—„ï¸ æ•°æ®åº“ç®¡ç†", "ğŸ¤– AI ç¼–å‰§åŠ©æ‰‹"])

# ==========================================
# Tab 1ï¼šæ¸…æ´—ä¸è½¬ç 
# ==========================================
with tab1:
    st.header("1. æ™ºèƒ½æ¸…æ´—ä¸é‡å‘½åæµæ°´çº¿")
    if 'analysis_data' not in st.session_state:
        st.session_state['analysis_data'] = None
    if 'process_done' not in st.session_state:
        st.session_state['process_done'] = False
    if 'processed_files' not in st.session_state:
        st.session_state['processed_files'] = []
    if 'show_success_celebration' not in st.session_state:
        st.session_state['show_success_celebration'] = None
    if 'pending_import' not in st.session_state:
        st.session_state['pending_import'] = None

    # --- å…¥åº“æˆåŠŸï¼šæ°”çƒä¸ Toast ---
    if st.session_state.get('show_success_celebration'):
        msg = st.session_state['show_success_celebration']
        if msg != "error":
            if st.session_state.get("easter_egg", True):
                st.balloons()
            st.toast(msg.get("toast", "å…¥åº“æˆåŠŸï¼"), icon=msg.get("icon", "ğŸ—„ï¸"))
        st.session_state['show_success_celebration'] = None

    # --- ä¸Šä¼ ä¸é¢„è¯†åˆ« ---
    uploaded_files = st.file_uploader("ç¬¬ä¸€æ­¥ï¼šä¸Šä¼ å­—å¹•æ–‡ä»¶", accept_multiple_files=True)
    if uploaded_files:
        if st.button("ğŸ” æ™ºèƒ½é¢„è¯†åˆ«åç§°"):
            with st.spinner("æ­£åœ¨è§£æ..."):
                st.session_state['analysis_data'] = core.analyze_filenames(uploaded_files)
                st.session_state['process_done'] = False

    # --- å…ƒæ•°æ®æ ¡å¯¹ä¸æ‰¹é‡å¤„ç† ---
    if st.session_state['analysis_data'] is not None:
        st.divider()
        st.subheader("ç¬¬äºŒæ­¥ï¼šç¡®è®¤å…ƒæ•°æ®")
        # âœ¨ æ–°å¢ï¼šæ‰¹é‡ä¿®æ”¹å·¥å…·æ 
        with st.expander("ğŸ› ï¸ æ‰¹é‡ä¿®æ”¹å·¥å…· (é’ˆå¯¹å‰§é›†å¯¼å…¥)", expanded=True):
            col_b1, col_b2, col_b3 = st.columns([2, 1, 1])
            with col_b1:
                bulk_title = st.text_input("ç»Ÿä¸€ä¿®æ”¹ç‰‡å", placeholder="è¾“å…¥æ­£ç¡®çš„å‰§é›†åç§°")
            with col_b2:
                bulk_year = st.number_input("ç»Ÿä¸€ä¿®æ”¹å¹´ä»½", min_value=1900, max_value=2100, value=2025)
            with col_b3:
                st.write("æ“ä½œ")
                if st.button("ğŸª„ ä¸€é”®åº”ç”¨åˆ°æ‰€æœ‰è¡Œ", use_container_width=True):
                    # ç›´æ¥ä¿®æ”¹ session_state ä¸­çš„æ•°æ®
                    for item in st.session_state['analysis_data']:
                        if bulk_title:
                            item['è¯†åˆ«ç‰‡å'] = bulk_title
                        if bulk_year:
                            item['å¹´ä»½'] = bulk_year
                    st.toast("å·²æ‰¹é‡æ›´æ–°å…ƒæ•°æ®ï¼")
                    st.rerun() # åˆ·æ–°ç•Œé¢ä»¥æ˜¾ç¤ºæ›´æ–°åçš„æ•°æ®
        edited_df = st.data_editor(
            pd.DataFrame(st.session_state['analysis_data']),
            column_config={
                "åŸå§‹æ–‡ä»¶å": st.column_config.Column(disabled=True),
                "è¯†åˆ«ç‰‡å": st.column_config.TextColumn("ç‰‡å"),
                "å¹´ä»½": st.column_config.NumberColumn("å¹´ä»½", format="%d"),
                "season_num": None, "episode_num": None,
            },
            use_container_width=True, hide_index=True
        )
        skip_embedding = st.checkbox(
            "âš¡ï¸ æé€Ÿå…¥åº“æ¨¡å¼ (æš‚ä¸ç”Ÿæˆ AI å‘é‡)", 
            value=False, 
            help="å‹¾é€‰åå°†è·³è¿‡ AI åˆ†æï¼Œå…¥åº“é€Ÿåº¦æå‡ 100 å€ï¼ä½†åœ¨ã€é‡å»ºç´¢å¼•ã€‘ä¹‹å‰ï¼Œè¿™äº›æ–‡ä»¶æ— æ³•é€šè¿‡ AI è¯­ä¹‰æœç´¢æ‰¾åˆ°ï¼ˆåªèƒ½ç”¨å…³é”®è¯æœï¼‰ã€‚"
        )

        if st.button("ğŸš€ æ‰¹é‡å¤„ç†", type="primary", use_container_width=True):
            with st.status("æ­£åœ¨å¤„ç†ï¼ˆè½¬ç ä¸è½ç›˜ï¼‰...", expanded=True) as status:
                model_instance = None
                if not skip_embedding:
                    try:
                        st.write("ğŸ§  æ­£åœ¨åŠ è½½/è·å– AI æ¨¡å‹...")
                        model_instance = load_embedding_model(selected_model)
                    except Exception as e:
                        st.error(str(e))
                        st.stop()
                else:
                    st.write("âš¡ï¸ å·²å¯ç”¨æé€Ÿæ¨¡å¼ï¼Œè·³è¿‡æ¨¡å‹åŠ è½½...")
                final_metadata = edited_df.to_dict('records')
                current_model_name = selected_model if not skip_embedding else None
                logs, processed_files, stats, pending_rows = core.process_only(
                    uploaded_files, final_metadata, library_path, model_instance,
                    model_name=current_model_name
                )
                st.session_state['process_logs'] = logs
                st.session_state['processed_files'] = processed_files
                if pending_rows:
                    st.session_state['pending_import'] = {'pending_rows': pending_rows, 'stats': stats}
                st.session_state['process_done'] = True
                status.update(label="âœ… å¤„ç†å®Œæˆï¼å‡†å¤‡å…¥åº“...", state="complete", expanded=False)
                time.sleep(1)
                st.rerun()
    # --- å¤„ç†æ—¥å¿— ---
    if st.session_state.get('process_logs'):
        st.divider()
        st.subheader("ğŸ“ å¤„ç†æ—¥å¿—")
        with st.expander("ç‚¹å‡»æŸ¥çœ‹è¯¦ç»†å¤„ç†è®°å½•", expanded=True):
            for log in st.session_state['process_logs']:
                if "âŒ" in log: st.error(log)
                elif "âš ï¸" in log: st.warning(log)
                else: st.success(log)
    # --- å…¥åº“å‰ç¡®è®¤ ---
    if st.session_state.get('pending_import'):
        st.divider()
        st.subheader("ç¬¬ä¸‰æ­¥ï¼šç¡®è®¤å…¥åº“")
        stats = st.session_state['pending_import']['stats']
        success, fail, dup = stats.get("success", 0), stats.get("fail", 0), stats.get("duplicate", 0)
        col1, col2, col3 = st.columns(3)
        col1.metric("âœ… æˆåŠŸ", success, "æ¡å¯å…¥åº“")
        col2.metric("âŒ å¤±è´¥", fail, "æ¡")
        col3.metric("âš ï¸ é‡å¤", dup, "å·²è·³è¿‡")
        st.caption("æ–‡ä»¶å·²ä¿å­˜åˆ°æœ¬åœ°ã€‚ç‚¹å‡»ã€Œç¡®è®¤å…¥åº“ã€å°†æŠŠä¸Šè¿°æˆåŠŸé¡¹å†™å…¥æ•°æ®åº“ï¼›ç‚¹å‡»ã€Œå–æ¶ˆã€åˆ™ä»…ä¿ç•™æœ¬åœ°æ–‡ä»¶ï¼Œä¸å…¥åº“ã€‚")
        confirm_col, cancel_col, _ = st.columns([1, 1, 4])
        with confirm_col:
            if st.button("ç¡®è®¤å…¥åº“", type="primary", use_container_width=True, key="confirm_import"):
                core.commit_pending_to_db(st.session_state['pending_import']['pending_rows'])
                st.session_state['pending_import'] = None
                cached_get_library_stats.clear()
                st.session_state['show_success_celebration'] = {"toast": "å…¥åº“æˆåŠŸï¼å¯åœ¨ã€Œæ•°æ®åº“ç®¡ç†ã€æ£€ç´¢", "icon": "ğŸ—„ï¸"}
                st.rerun()
        with cancel_col:
            if st.button("å–æ¶ˆ", use_container_width=True, key="cancel_import"):
                st.session_state['pending_import'] = None
                st.rerun()
    # --- ä¸‹è½½åŒºï¼šå•æ–‡ä»¶ + å¤šæ–‡ä»¶ ZIP ---
    if st.session_state['process_done'] and st.session_state['processed_files']:
        st.divider()
        st.subheader("ğŸ“¥ ä¸‹è½½è½¬ç åçš„ SRT æ–‡ä»¶")
        files = st.session_state['processed_files']
        if st.session_state.get('pending_import'):
            st.caption("æ–‡ä»¶å·²ä¿å­˜åˆ°æœ¬åœ°ï¼›ç¡®è®¤å…¥åº“åå¯åœ¨ã€Œæ•°æ®åº“ç®¡ç†ã€ä¸­æ£€ç´¢ã€‚")
        else:
            st.caption("ä¸Šè¿°æ–‡ä»¶å·²ä¿å­˜åˆ°æœ¬åœ°å¹¶å†™å…¥æ•°æ®åº“ï¼Œå¯åœ¨ã€Œæ•°æ®åº“ç®¡ç†ã€ä¸­æ£€ç´¢ã€‚")
        if len(files) > 1:
            buf = io.BytesIO()
            with zipfile.ZipFile(buf, "w", zipfile.ZIP_DEFLATED) as zf:
                for f in files:
                    name = f.get("name", f.get("filename", getattr(f, "name", "unknown.srt")))
                    content = f.get("content", getattr(f, "content", ""))
                    if content is None:
                        content = ""
                    if isinstance(content, bytes):
                        content = content.decode("utf-8", errors="replace")
                    zf.writestr(name, content)
            buf.seek(0)
            st.download_button(
                label="ğŸ“¦ æ‰¹é‡ä¸‹è½½ (ZIP å‹ç¼©åŒ…)",
                data=buf.getvalue(),
                file_name="subtitles.zip",
                mime="application/zip",
                use_container_width=True,
                key="batch_zip_dl"
            )
        with st.container(border=True):
            for i, f in enumerate(files):
                name = f.get("name", f.get("filename", getattr(f, "name", "unknown.srt")))
                content = f.get("content", getattr(f, "content", None))
                if content is None and hasattr(f, "read"):
                    try:
                        f.seek(0)
                        content = f.read()
                        if isinstance(content, bytes):
                            content = content.decode("utf-8", errors="replace")
                    except Exception:
                        content = ""
                content = content or ""
                c_name, c_btn = st.columns([3, 1])
                c_name.write(f"ğŸ“„ {name}")
                if content:
                    c_btn.download_button(
                        label="ç‚¹å‡»ä¸‹è½½",
                        data=content,
                        file_name=name,
                        mime="text/plain",
                        key=f"dl_{i}_{name}_{i}",
                    )
                else:
                    c_btn.warning("æ–‡ä»¶ä¸ºç©º")

# ==========================================
# Tab 2ï¼šæ•°æ®åº“ç®¡ç†
# ==========================================
with tab2:
    st.header("2. æ ¸å¿ƒæ•°æ®åº“ (Memory Bank)")
    stats = cached_get_library_stats()
    with st.container(border=True):
        m1, m2, m3 = st.columns(3)
        m1.metric("ğŸ“š å·²æ”¶å½•ç”µå½±/å‰§é›†", f"{stats['movie_count']} éƒ¨")
        m2.metric("ğŸ’¬ å°è¯æ€»è¡Œæ•°", f"{stats['line_count']} è¡Œ")
        m3.metric("â±ï¸ æœ€åæ›´æ–°", stats['last_update'])
    st.divider()

    # --- åº“ç»´æŠ¤ï¼šæ‰«æä¸æ¸…ç† ---
    c1, c2 = st.columns([3, 1])
    with c1:
        st.info(f"å½“å‰ç›‘æ§çš„ç¡¬ç›˜è·¯å¾„: `{library_path}`")
    with c2:
        sync_btn = st.button("ğŸ”„ é‡æ–°æ‰«æç¡¬ç›˜ & é‡å»ºç´¢å¼•", use_container_width=True)
    if 'scan_result' not in st.session_state:
        st.session_state['scan_result'] = None
    if sync_btn:
        with st.status("æ­£åœ¨æ·±åº¦éå†ç¡¬ç›˜...", expanded=True) as status:
            try:
                st.write("ğŸ§  æ­£åœ¨åˆå§‹åŒ– AI æ¨¡å‹...")
                model_instance = load_embedding_model(selected_model)
            except Exception as e:
                status.update(label="âŒ æ¨¡å‹åŠ è½½å¤±è´¥", state="error")
                st.error(str(e))
                st.stop()
            for log, data in core.scan_library_path(library_path, model_instance, model_name=selected_model):
                if log == "DONE":
                    st.session_state['scan_result'] = data
                    status.update(label="âœ… æ‰«æå®Œæˆ", state="complete")
                    st.session_state['config']['embedding_model'] = selected_model
                    with open(CONFIG_FILE, 'w') as f:
                        json.dump(st.session_state['config'], f)
                else:
                    st.write(log)
            if st.session_state.get('scan_result') and st.session_state['scan_result'].get('success'):
                st.toast("ç´¢å¼•æ›´æ–°å®Œæ¯•ï¼", icon="ğŸ‰")
                time.sleep(1)
                st.rerun()
    if st.session_state.get('scan_result') and st.session_state['scan_result'].get('success'):
        res = st.session_state['scan_result']
        if res['new_added'] > 0:
            st.success(f"ğŸ‰ æˆåŠŸå…¥åº“ {res['new_added']} éƒ¨æ–°å½±ç‰‡ï¼")
        missing_count = len(res['missing_files'])
        if missing_count > 0:
            st.warning(f"âš ï¸ å‘ç°æ•°æ®åº“ä¸­æœ‰ {missing_count} ä¸ªæ–‡ä»¶åœ¨ç¡¬ç›˜ä¸Šæ‰¾ä¸åˆ°äº†ã€‚")
            with st.expander("æŸ¥çœ‹ä¸¢å¤±æ–‡ä»¶åˆ—è¡¨", expanded=False):
                for f in res['missing_files'][:10]:
                    st.code(f, language="text")
                if missing_count > 10:
                    st.caption(f"... ä»¥åŠå…¶ä»– {missing_count - 10} ä¸ªæ–‡ä»¶")
            col_del_text, col_del_btn = st.columns([3, 1])
            with col_del_text:
                st.write("è¿™äº›æ˜¯æ— æ•ˆçš„'å¹½çµè®°å½•'ï¼Œå»ºè®®æ¸…ç†ã€‚")
            with col_del_btn:
                if st.button("ğŸ—‘ï¸ ç¡®è®¤æ¸…ç†æ— æ•ˆè®°å½•", type="primary", use_container_width=True):
                    success, msg = core.delete_missing_records(res['missing_files'])
                    if success:
                        st.success(msg)
                        st.session_state['scan_result'] = None
                        time.sleep(1)
                        st.rerun()
                    else:
                        st.error(msg)
        elif res['new_added'] == 0:
            st.info("æ•°æ®åº“ä¸ç¡¬ç›˜å®Œå…¨åŒæ­¥ï¼Œæœªå‘ç°å˜åŠ¨ã€‚")
    st.divider()

    # --- æ™ºèƒ½æ£€ç´¢ï¼šå…³é”®è¯ / è¯­ä¹‰ ---
    st.subheader("ğŸ” æ™ºèƒ½æ£€ç´¢å°")
    query = st.text_input("è¯·è¾“å…¥æ£€ç´¢å†…å®¹", placeholder="è¾“å…¥å…³é”®è¯ï¼ˆå¦‚ï¼šé’±ï¼‰æˆ– æŠ½è±¡æ¦‚å¿µï¼ˆå¦‚ï¼šå‹æƒ…ã€é—æ†¾ï¼‰...", key="search_query")
    col_btn1, col_btn2, col_space = st.columns([1, 1, 4])
    with col_btn1:
        btn_keyword = st.button("ğŸ” å…³é”®è¯åŒ¹é…", use_container_width=True)
    with col_btn2:
        btn_semantic = st.button("ğŸ§  AI è¯­ä¹‰æœç´¢", use_container_width=True, type="primary")

    if btn_keyword and query:
        st.info(f"æ­£åœ¨è¿›è¡Œã€å…³é”®è¯ã€‘ç²¾ç¡®åŒ¹é…ï¼š'{query}' ...")
        results = core.search_db_keyword(query)
        st.write(f"æ‰¾åˆ° {len(results)} æ¡è®°å½•ï¼š")
        for res in results:
            with st.container(border=True):
                if res['season'] > 0 or res['episode'] > 0:
                    ep_info = f" `S{str(res['season']).zfill(2)}E{str(res['episode']).zfill(2)}`"
                else:
                    ep_info = ""
                st.markdown(f"**ğŸ¬ {res['movie']}**{ep_info} `[{res['time']}]`")
                st.text(res['content'])

    if btn_semantic and query:
        results = None
        with st.status("ğŸ§  AI æ­£åœ¨æ€è€ƒ...", expanded=True) as status:
            try:
                model_instance = load_embedding_model(selected_model)
                st.write("1. å‘é‡åŒ– (Embedding)...")
                results = core.search_db_semantic(query, model_instance)
                status.update(label="âœ… è¯­ä¹‰åŒ¹é…å®Œæˆï¼", state="complete", expanded=False)
            except Exception as e:
                status.update(label="âŒ æœç´¢å‡ºé”™", state="error")
                st.error(f"æœç´¢å¤±è´¥: {e}")
                st.stop()
        if results is not None:
            st.success(f"AI è”æƒ³åˆ°äº† {len(results)} æ¡ç›¸å…³å†…å®¹ï¼š")
            for res in results:
                with st.container(border=True):
                    ep = f" S{str(res['season']).zfill(2)}E{str(res['episode']).zfill(2)}" if (res.get('season') or 0) or (res.get('episode') or 0) else ""
                    st.markdown(f"**ğŸ¤– {res['movie']}**{ep} `[{res['time']}]`")
                    st.markdown(f"> *{res['content']}*")

# ==========================================
# Tab 3ï¼šAI æ··å‰ªå®éªŒå®¤
# ==========================================
with tab3:
    st.header("3. AI ç¼–å‰§æŒ‡æŒ¥å°")
    st.caption("åŸºäºè¯­ä¹‰åº“çš„æ™ºèƒ½å‰§æœ¬ç”Ÿæˆç³»ç»Ÿ")
    # --- çŠ¶æ€ä¸åˆ›ä½œåŒº ---
    llm_cfg = st.session_state.get('llm_config', {})
    has_key = bool(llm_cfg.get('api_key')) or llm_cfg.get('provider') == "Local (Ollama)"
    if has_key:
        st.success(f"ğŸŸ¢ AI å¼•æ“å°±ç»ª: {llm_cfg.get('provider')} ({llm_cfg.get('model_name')})")
    else:
        st.warning("âš ï¸ AI å¼•æ“æœªé…ç½®ï¼šè¯·ç‚¹å‡»å·¦ä¾§ä¾§è¾¹æ çš„ã€ŒğŸ”‘ LLM å¤§æ¨¡å‹é…ç½®ã€å¡«å…¥ API Keyã€‚")

    st.divider()
    c1, c2 = st.columns([3, 1])
    with c1:
        movie_list = core.get_all_movies()
        selected_movie = st.selectbox(
            "ğŸ“‚ æ ¸å¿ƒç´ ææ¥æº", 
            ["(å…¨åº“ç»¼åˆæœç´¢)"] + movie_list,
            help="é€‰æ‹©å…·ä½“çš„ç”µå½±ï¼ŒAI å°†ä¼˜å…ˆä½¿ç”¨è¯¥ç”µå½±çš„å°è¯ï¼›é€‰å…¨åº“åˆ™ä¼šè·¨ç”µå½±æ··å‰ªã€‚"
        )
    with c2:
        script_style = st.selectbox("ğŸ­ è„šæœ¬é£æ ¼", ["æƒ…æ„Ÿæ··å‰ª (é—æ†¾/æ²»æ„ˆ)", "ç‡ƒå‘è¸©ç‚¹ (åŠ¨ä½œ/åŠ±å¿—)", "é¢„å‘Šç‰‡ (æ‚¬ç–‘/æƒŠæ‚š)"])
        allow_vo = st.toggle("ğŸ¤ å…è®¸ç”Ÿæˆæ—ç™½ (VO)", value=True, help="å‹¾é€‰åï¼ŒAI ä¼šåœ¨å°è¯ä¹‹é—´åŠ å…¥æ·±æ²‰æˆ–æ²»æ„ˆçš„æ—ç™½ä½œä¸ºè¡”æ¥ã€‚")
    default_prompt = """ä¸»é¢˜ï¼šå…³äºã€æ—¶é—´ä¸é—æ†¾ã€‘
è¦æ±‚ï¼š
1. å¼€å¤´è¦æ…¢ï¼Œç”¨å‡ å¥å…³äºâ€œé”™è¿‡â€çš„å°è¯é“ºå«ã€‚
2. ä¸­æ®µèŠ‚å¥åŠ å¿«ï¼Œå±•ç¤ºäººç”Ÿä¸­çš„ä¸åŒé˜¶æ®µã€‚
3. ç»“å°¾è¦æœ‰ä¸€å¥æŒ¯è‹å‘è©çš„é‡‘å¥ï¼Œå‡åä¸»é¢˜ã€‚
4. ä¸éœ€è¦æ—ç™½ï¼Œå…¨éƒ¨ç”¨ç”µå½±åŸå£°å°è¯ã€‚"""
    prompt_text = st.text_area(
        "ğŸ“ å¯¼æ¼”æŒ‡ä»¤ (Prompt)", 
        value=default_prompt, 
        height=200,
        placeholder="åœ¨è¿™é‡Œå‘Šè¯‰ AI ä½ æƒ³å‰ªè¾‘ä»€ä¹ˆæ ·çš„è§†é¢‘..."
    )
    col1, col2 = st.columns([1, 1])
    with col1:
        # âœ¨ æ–°å¢å¼€å…³
        allow_dup = st.checkbox("å…è®¸é‡å¤å°è¯ (å°è¯æ··å‰ªæ¨¡å¼)", value=False, help="å¦‚æœä½ æƒ³åš'10éƒ¨ç”µå½±è¯´åŒä¸€å¥è¯'çš„æ··å‰ªï¼Œè¯·å‹¾é€‰æ­¤é¡¹ã€‚")
    
    generate_btn = st.button("ğŸš€ ç”Ÿæˆæ··å‰ªè„šæœ¬", type="primary", use_container_width=True, disabled=not has_key)
    if generate_btn:
        with st.status("ğŸ¬ AI æ­£åœ¨åˆ›ä½œå‰§æœ¬...", expanded=True) as status:
            try:
                # 1. è¯­ä¹‰æ£€ç´¢ (RAG æ ¸å¿ƒæ­¥éª¤)
                st.write("1. ğŸ” æ­£åœ¨ä»æ•°æ®åº“æ£€ç´¢ç›¸å…³å°è¯ä¸æ—¶é—´ç ...")
                
                # å¦‚æœæ˜¯å…¨åº“æœç´¢ï¼Œå°±ç”¨ç”¨æˆ·çš„ Prompt å»æœï¼›å¦‚æœæ˜¯ç‰¹å®šç”µå½±ï¼Œå°±å…ˆæœç”µå½±å†è¿‡æ»¤
                # è¿™é‡Œä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬ç›´æ¥ç”¨ç”¨æˆ·çš„ Prompt å»åšè¯­ä¹‰æœç´¢
                search_query = prompt_text[:200] # æˆªå–ä¸€éƒ¨åˆ†ä½œä¸ºæœç´¢è¯
                
                # è°ƒç”¨ core çš„æœç´¢åŠŸèƒ½ (æ³¨æ„ï¼šéœ€è¦ç¡®ä¿ core_logic æœ‰ search_db_semantic)
                # 1. åŠ è½½æ¨¡å‹
                model_instance = load_embedding_model(st.session_state['config']['embedding_model'])
                
                # 2. ç¡®å®šç­›é€‰æ¡ä»¶ï¼ˆæ³¨æ„ç¼©è¿›å¿…é¡»å¯¹é½ï¼‰
                filter_movie = None if selected_movie == "(å…¨åº“ç»¼åˆæœç´¢)" else selected_movie

                # 3. è°ƒç”¨ä¼˜åŒ–åçš„è¯­ä¹‰æœç´¢
                search_results = core.search_db_semantic_optimized(
                    search_query, 
                    model_instance, 
                    final_k=30, 
                    db_path=st.session_state['config']['db_path'],
                    allow_duplicates=allow_dup,
                    target_movie=filter_movie  # ğŸ‘ˆ å¿…é¡»ä¼ ç»™ core å±‚
                )
                
                if not search_results:
                    st.error("âŒ æœªæ‰¾åˆ°ç›¸å…³ç´ æï¼Œè¯·å°è¯•æ›´æ¢å…³é”®è¯ã€‚")
                    st.stop()

                # 2. æ„å»ºä¸Šä¸‹æ–‡ (Context Construction)
                st.write(f"2. ğŸ§  æ­£åœ¨ç­›é€‰å¹¶ç»„è£… {len(search_results)} æ¡ç´ æ...")
                
                context_text = ""
                for res in search_results:
                    # --- æ ¸å¿ƒï¼šæ ¼å¼åŒ–æ¥æºå­—ç¬¦ä¸² ---
                    # æ ¼å¼ï¼š[ã€Šç”µå½±åã€‹S01E02 00:12:30]
                    source_tag = f"ã€Š{res['movie']}ã€‹"
                    if res.get('season') and res.get('episode'):
                         source_tag += f"S{str(res['season']).zfill(2)}E{str(res['episode']).zfill(2)}"
                    
                    timestamp = res['time']
                    full_tag = f"[{source_tag} {timestamp}]"
                    
                    # æ‹¼æ¥åˆ°ä¸Šä¸‹æ–‡é‡Œï¼Œå–‚ç»™ AI
                    context_text += f"ç´ æID: {full_tag}\nå°è¯å†…å®¹: {res['content']}\n\n"

                # 3. ç»„è£…æœ€ç»ˆ Prompt
                st.write(f"3. âœï¸ æ­£åœ¨è¯·æ±‚ {llm_cfg.get('model_name')} ç”Ÿæˆåˆ†é•œ...")
                
                system_prompt = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†é¢‘å‰ªè¾‘å¸ˆã€‚è¯·æ ¹æ®ç”¨æˆ·æä¾›çš„ã€ç´ æåº“ã€‘æ’°å†™å‰ªè¾‘è„šæœ¬ã€‚

ã€ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†é¢‘å‰ªè¾‘å¸ˆã€‚è¯·æ ¹æ®ç”¨æˆ·æä¾›çš„ã€ç´ æåº“ã€‘æ’°å†™å‰ªè¾‘è„šæœ¬ã€‚

ã€åˆ›ä½œè§„åˆ™ã€‘
1. **åŸå£°ä¼˜å…ˆ**ï¼šæ ¸å¿ƒæƒ…æ„Ÿå’Œå…³é”®è½¬æŠ˜å°½é‡ä½¿ç”¨ç´ æåº“ä¸­çš„å°è¯ï¼Œå¹¶æ ‡æ³¨ã€æ—¶é—´ç æ¥æºã€‘ã€‚
2. **æ—ç™½è¡”æ¥**ï¼šå…è®¸åŠ å…¥ã€æ—ç™½ (Voiceover)ã€‘æ¥è¡”æ¥å‰§æƒ…ã€æ¸²æŸ“æ°›å›´æˆ–äº¤ä»£èƒŒæ™¯ã€‚æ—ç™½åº”å…·æœ‰ç”µå½±æ„Ÿã€‚
3. **æ ¼å¼åŒºåˆ†**ï¼š
   - æ—ç™½è¯·æ ‡æ³¨ä¸ºï¼š**ã€æ—ç™½ã€‘**ï¼šâ€œ......â€
   - åŸå£°è¯·æ ‡æ³¨ä¸ºï¼š**[ã€Šç‰‡åã€‹00:00:00] ã€è§’è‰²ã€‘**ï¼šâ€œ......â€
4. **è¾“å‡ºæ ¼å¼**ï¼šMarkdown è¡¨æ ¼æˆ–æ¸…æ™°çš„åˆ†é•œåˆ—è¡¨ã€‚
"""

                vo_instruction = "å…è®¸åŠ å…¥æ—ç™½ä»¥å¢å¼ºæ„ŸæŸ“åŠ›ã€‚" if allow_vo else "ä¸¥æ ¼ç¦æ­¢æ—ç™½ï¼Œä»…ä½¿ç”¨åŸå£°å°è¯ã€‚"
                user_prompt_final = f"""
ã€æ—ç™½è¦æ±‚ã€‘
{vo_instruction}
ã€æ ¸å¿ƒåˆ›ä½œé£æ ¼ã€‘
æœ¬æ¬¡è§†é¢‘çš„ä¸»åŸºè°ƒæ˜¯ï¼š{script_style}ã€‚è¯·åœ¨ç”»é¢æè¿°å’Œè½¬åœºèŠ‚å¥ä¸­å……åˆ†ä½“ç°è¿™ç§é£æ ¼ã€‚

ã€ç”¨æˆ·å…·ä½“éœ€æ±‚ã€‘
{prompt_text}

ã€å¯ç”¨ç´ æåº“ (Reference Material)ã€‘
{context_text}

è¯·å¼€å§‹ç¼–å†™è„šæœ¬ï¼š
"""

                # 4. è°ƒç”¨ LLM (ä¼ å…¥ UI é…ç½®çš„æ‰€æœ‰å‚æ•°)
                response = core.call_llm_api(
                    system_prompt, 
                    user_prompt_final, 
                    llm_cfg['api_key'],
                    model_name=llm_cfg['model_name'], # ğŸ‘ˆ ä¼ å…¥é€‰ä¸­çš„æ¨¡å‹å
                    base_url=llm_cfg['base_url']      # ğŸ‘ˆ ä¼ å…¥é…ç½®çš„ Base URL
                )
                
                status.update(label="âœ… åˆ›ä½œå®Œæˆï¼", state="complete", expanded=False)
                
                st.divider()
                st.subheader("ğŸ“„ åŒ…å«æ—¶é—´ç çš„æ··å‰ªè„šæœ¬")
                st.markdown(response)
                
                # ä¸‹è½½æŒ‰é’®
                st.download_button(
                    label="ğŸ“¥ å¯¼å‡ºè„šæœ¬ (.md)",
                    data=response,
                    file_name=f"script_with_timecode_{int(time.time())}.md",
                    mime="text/markdown"
                )

            except Exception as e:
                status.update(label="âŒ ç”Ÿæˆå¤±è´¥", state="error")
                st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
                # æ‰“å°å †æ ˆä»¥ä¾¿è°ƒè¯•
                import traceback
                st.code(traceback.format_exc())