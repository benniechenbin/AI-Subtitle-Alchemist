import json
import os
import io
import zipfile
import streamlit as st
import core_logic as core
import pandas as pd
import time
from sentence_transformers import SentenceTransformer

# ==========================================
# ç¼“å­˜ä¸é¡µé¢åŸºç¡€
# ==========================================
@st.cache_data(ttl=60)
def cached_get_library_stats():
    return core.get_library_stats()

st.set_page_config(
    page_title="AI å­—å¹•ç‚¼é‡‘æœ¯å¸ˆ",
    page_icon="ğŸ¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==========================================
# æ¨¡å‹åŠ è½½å™¨ (ç¼“å­˜)
# ==========================================
@st.cache_resource(show_spinner="æ­£åœ¨åŠ è½½ AI æ¨¡å‹ï¼Œè¯·ç¨å€™...")
def load_embedding_model(model_name):
    try:
        print(f"ğŸ”„ Cache Miss: æ­£åœ¨åŠ è½½æ¨¡å‹ {model_name}...")
        return SentenceTransformer(model_name)
    except Exception as e:
        raise RuntimeError(f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")

# ==========================================
# ä¾§è¾¹æ ï¼šå…¨å±€æ§åˆ¶
# ==========================================
with st.sidebar:
    st.title("ğŸ›ï¸ æ§åˆ¶å°")
    CONFIG_FILE = "config.json"
    if 'config_loaded' not in st.session_state:
        if os.path.exists(CONFIG_FILE):
            with open(CONFIG_FILE, 'r') as f:
                st.session_state['config'] = json.load(f)
        else:
            default_path = os.path.join(os.path.expanduser("~"), "Movies", "Subtitles")
            
            # å¦‚æœæ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼Œç”šè‡³å¯ä»¥è´´å¿ƒåœ°è‡ªåŠ¨åˆ›å»ºï¼ˆå¯é€‰ï¼‰
            if not os.path.exists(default_path):
                try:
                    os.makedirs(default_path)
                except:
                    pass

            st.session_state['config'] = {
                'library_path': default_path,  # <--- ä½¿ç”¨å˜é‡
                'embedding_model': "moka-ai/m3e-base"
            }
        st.session_state['config_loaded'] = True

    def save_config():
        st.session_state['config']['library_path'] = st.session_state['path_input']
        with open(CONFIG_FILE, 'w') as f:
            json.dump(st.session_state['config'], f)
        st.toast("âœ… è·¯å¾„é…ç½®å·²ä¿å­˜")
        cached_get_library_stats.clear()

    library_path = st.text_input(
        "ğŸ“‚ å­—å¹•åº“æ ¹ç›®å½•",
        value=st.session_state['config']['library_path'],
        key="path_input",
        on_change=save_config
    )
    # --- è¯­ä¹‰æ¨¡å‹é€‰æ‹© ---
    model_options = {
        "paraphrase-multilingual-MiniLM-L12-v2": "ğŸš€ æé€Ÿç‰ˆ (MiniLM - æ¨è)",
        "moka-ai/m3e-base": "ğŸ‡¨ğŸ‡³ ä¸­æ–‡æ ‡å‡†ç‰ˆ (M3E - é»˜è®¤)",
        "BAAI/bge-m3": "ğŸ”¥ æ——èˆ°ç‰ˆ (BGE-M3 - è¾ƒæ…¢)",
        "custom": "ğŸ› ï¸ è‡ªå®šä¹‰ (æ‰‹åŠ¨è¾“å…¥æ¨¡å‹ID)"
    }
    current_config_model = st.session_state['config'].get('embedding_model', "moka-ai/m3e-base")
    if current_config_model in model_options:
        default_index = list(model_options.keys()).index(current_config_model)
        radio_key_value = current_config_model
    else:
        default_index = list(model_options.keys()).index("custom")
        radio_key_value = "custom"
    selected_option = st.selectbox(
        "ğŸ§  è¯­ä¹‰æ¨¡å‹ (Embedding)",
        options=list(model_options.keys()),
        format_func=lambda x: model_options[x],
        index=default_index,
        key="model_select_box",
        help="å†³å®šäº†AIå¦‚ä½•ç†è§£ä¸­æ–‡ã€‚å»ºè®®ä½¿ç”¨ M3Eã€‚"
    )
    if selected_option == "custom":
        custom_model_id = st.text_input(
            "è¾“å…¥ HuggingFace ID æˆ– æœ¬åœ°è·¯å¾„",
            value=current_config_model if radio_key_value == "custom" else "sentence-transformers/all-mpnet-base-v2",
            help="ä¾‹å¦‚ï¼šintfloat/multilingual-e5-large"
        )
        selected_model = custom_model_id.strip() if custom_model_id else "moka-ai/m3e-base"
    else:
        selected_model = selected_option
    if selected_model != current_config_model:
        st.divider()
        st.info(f"å‡†å¤‡åˆ‡æ¢ä¸ºï¼š{selected_model}")
        st.warning(
            "âš ï¸ æ¨¡å‹å·²å˜æ›´ï¼\n\nè¯·åŠ¡å¿…å»ã€Œæ•°æ®åº“ç®¡ç†ã€ç‚¹å‡»ã€Œé‡æ–°æ‰«æã€ï¼Œå¦åˆ™æ— æ³•ä½¿ç”¨æ–°æ¨¡å‹æœç´¢ï¼", 
            icon="ğŸš¨"
        )
    st.divider()
    st.toggle("ğŸ‰ å¯ç”¨å…¥åº“å½©è›‹", value=st.session_state.get("easter_egg", True), key="easter_egg")
    st.divider()
    # --- LLM å¤§æ¨¡å‹é…ç½®ï¼ˆæŠ˜å ï¼‰---
    with st.expander("ğŸ”‘ LLM å¤§æ¨¡å‹é…ç½® (å…¨å±€)", expanded=False):
        cfg = st.session_state['config']
        default_provider = cfg.get('llm_provider', "DeepSeek")
        default_key = cfg.get('llm_key', "")
        default_base = cfg.get('llm_base_url', "https://api.deepseek.com")
        provider = st.selectbox(
            "å‚å•†", 
            ["DeepSeek", "OpenAI", "Google", "Custom", "Local (Ollama)"],
            index=["DeepSeek", "OpenAI", "Google", "Custom", "Local (Ollama)"].index(default_provider) if default_provider in ["DeepSeek", "OpenAI", "Google", "Custom", "Local (Ollama)"] else 0,
            key="llm_provider"
        )
        api_key = st.text_input("API Key", value=default_key, type="password", key="llm_key_input", help="DeepSeek æˆ– OpenAI çš„ SK")
        model_presets = {
            "DeepSeek": ["deepseek-chat", "deepseek-reasoner"], # V3 å’Œ R1
            "OpenAI": ["gpt-4o", "gpt-4o-mini", "gpt-4-turbo"],
            "Google": ["gemini-1.5-pro", "gemini-1.5-flash"],
            "Local (Ollama)": ["llama3", "qwen2.5", "mistral"], # å¸¸ç”¨æœ¬åœ°æ¨¡å‹
            "Custom": []
        }
        current_model_val = cfg.get('llm_model_name', "")
        if provider in model_presets and model_presets[provider]:
            options = model_presets[provider] + ["âœï¸ æ‰‹åŠ¨è¾“å…¥..."]
            try:
                pre_index = options.index(current_model_val)
            except ValueError:
                pre_index = 0
            selected_preset = st.selectbox("æ¨¡å‹ç‰ˆæœ¬", options, index=pre_index, key="llm_model_select")
            
            if selected_preset == "âœï¸ æ‰‹åŠ¨è¾“å…¥...":
                model_name = st.text_input("è¯·è¾“å…¥æ¨¡å‹ ID", value=current_model_val, placeholder="ä¾‹å¦‚: deepseek-coder", key="llm_model_manual")
            else:
                model_name = selected_preset
        else:
            model_name = st.text_input("æ¨¡å‹åç§°", value=current_model_val, placeholder="å¦‚ llama3", key="llm_model_manual_only")
        placeholder_base = "https://api.deepseek.com"
        auto_fill_base = default_base
        
        if provider == "DeepSeek": 
            placeholder_base = "https://api.deepseek.com"
            if "openai" in default_base or "localhost" in default_base: auto_fill_base = placeholder_base
        elif provider == "OpenAI": 
            placeholder_base = "https://api.openai.com/v1"
            if "deepseek" in default_base: auto_fill_base = placeholder_base
        elif provider == "Local (Ollama)":
            placeholder_base = "http://localhost:11434/v1"
        base_url = st.text_input("Base URL", value=auto_fill_base, placeholder=placeholder_base, key="llm_base_input")
        if st.button("ğŸ’¾ ä¿å­˜é…ç½®", use_container_width=True):
            st.session_state['config']['llm_provider'] = provider
            st.session_state['config']['llm_key'] = api_key
            st.session_state['config']['llm_base_url'] = base_url
            st.session_state['config']['llm_model_name'] = model_name
            
            with open(CONFIG_FILE, 'w') as f:
                json.dump(st.session_state['config'], f)
            st.toast(f"âœ… å·²ä¿å­˜ï¼šä½¿ç”¨ {provider} - {model_name}")
            time.sleep(1)
            st.rerun()
        st.session_state['llm_config'] = {
            "provider": provider,
            "api_key": api_key,
            "base_url": base_url,
            "model_name": model_name
        }

# ==========================================
# ä¸»ç•Œé¢æ ‡é¢˜ä¸ Tab å¯¼èˆª
# ==========================================
st.title("ğŸ¬ AI å­—å¹•ç‚¼é‡‘æœ¯å¸ˆ")
st.markdown("Automated Subtitle Processing & AI Script Generation System")
tab1, tab2, tab3 = st.tabs(["ğŸ§¹ æ¸…æ´—ä¸è½¬ç ", "ğŸ—„ï¸ æ•°æ®åº“ç®¡ç†", "ğŸ¤– AI ç¼–å‰§åŠ©æ‰‹"])

# ==========================================
# Tab 1ï¼šæ¸…æ´—ä¸è½¬ç 
# ==========================================
with tab1:
    st.header("1. æ™ºèƒ½æ¸…æ´—ä¸é‡å‘½åæµæ°´çº¿")
    if 'analysis_data' not in st.session_state:
        st.session_state['analysis_data'] = None
    if 'process_done' not in st.session_state:
        st.session_state['process_done'] = False
    if 'processed_files' not in st.session_state:
        st.session_state['processed_files'] = []
    if 'show_success_celebration' not in st.session_state:
        st.session_state['show_success_celebration'] = None
    if 'pending_import' not in st.session_state:
        st.session_state['pending_import'] = None

    # --- å…¥åº“æˆåŠŸï¼šæ°”çƒä¸ Toast ---
    if st.session_state.get('show_success_celebration'):
        msg = st.session_state['show_success_celebration']
        if msg != "error":
            if st.session_state.get("easter_egg", True):
                st.balloons()
            st.toast(msg.get("toast", "å…¥åº“æˆåŠŸï¼"), icon=msg.get("icon", "ğŸ—„ï¸"))
        st.session_state['show_success_celebration'] = None

    # --- ä¸Šä¼ ä¸é¢„è¯†åˆ« ---
    uploaded_files = st.file_uploader("ç¬¬ä¸€æ­¥ï¼šä¸Šä¼ å­—å¹•æ–‡ä»¶", accept_multiple_files=True)
    if uploaded_files:
        if st.button("ğŸ” æ™ºèƒ½é¢„è¯†åˆ«åç§°"):
            with st.spinner("æ­£åœ¨è§£æ..."):
                st.session_state['analysis_data'] = core.analyze_filenames(uploaded_files)
                st.session_state['process_done'] = False

    # --- å…ƒæ•°æ®æ ¡å¯¹ä¸æ‰¹é‡å¤„ç† ---
    if st.session_state['analysis_data'] is not None:
        st.divider()
        st.subheader("ç¬¬äºŒæ­¥ï¼šç¡®è®¤å…ƒæ•°æ®")
        edited_df = st.data_editor(
            pd.DataFrame(st.session_state['analysis_data']),
            column_config={
                "åŸå§‹æ–‡ä»¶å": st.column_config.Column(disabled=True),
                "è¯†åˆ«ç‰‡å": st.column_config.TextColumn("ç‰‡å"),
                "å¹´ä»½": st.column_config.NumberColumn("å¹´ä»½", format="%d"),
                "season_num": None, "episode_num": None,
            },
            use_container_width=True, hide_index=True
        )
        skip_embedding = st.checkbox(
            "âš¡ï¸ æé€Ÿå…¥åº“æ¨¡å¼ (æš‚ä¸ç”Ÿæˆ AI å‘é‡)", 
            value=False, 
            help="å‹¾é€‰åå°†è·³è¿‡ AI åˆ†æï¼Œå…¥åº“é€Ÿåº¦æå‡ 100 å€ï¼ä½†åœ¨ã€é‡å»ºç´¢å¼•ã€‘ä¹‹å‰ï¼Œè¿™äº›æ–‡ä»¶æ— æ³•é€šè¿‡ AI è¯­ä¹‰æœç´¢æ‰¾åˆ°ï¼ˆåªèƒ½ç”¨å…³é”®è¯æœï¼‰ã€‚"
        )

        if st.button("ğŸš€ æ‰¹é‡å¤„ç†", type="primary", use_container_width=True):
            with st.status("æ­£åœ¨å¤„ç†ï¼ˆè½¬ç ä¸è½ç›˜ï¼‰...", expanded=True) as status:
                model_instance = None
                if not skip_embedding:
                    try:
                        st.write("ğŸ§  æ­£åœ¨åŠ è½½/è·å– AI æ¨¡å‹...")
                        model_instance = load_embedding_model(selected_model)
                    except Exception as e:
                        st.error(str(e))
                        st.stop()
                else:
                    st.write("âš¡ï¸ å·²å¯ç”¨æé€Ÿæ¨¡å¼ï¼Œè·³è¿‡æ¨¡å‹åŠ è½½...")
                final_metadata = edited_df.to_dict('records')
                current_model_name = selected_model if not skip_embedding else None
                logs, processed_files, stats, pending_rows = core.process_only(
                    uploaded_files, final_metadata, library_path, model_instance,
                    model_name=current_model_name
                )
                st.session_state['process_logs'] = logs
                st.session_state['processed_files'] = processed_files
                if pending_rows:
                    st.session_state['pending_import'] = {'pending_rows': pending_rows, 'stats': stats}
                st.session_state['process_done'] = True
                status.update(label="âœ… å¤„ç†å®Œæˆï¼å‡†å¤‡å…¥åº“...", state="complete", expanded=False)
                time.sleep(1)
                st.rerun()
    # --- å¤„ç†æ—¥å¿— ---
    if st.session_state.get('process_logs'):
        st.divider()
        st.subheader("ğŸ“ å¤„ç†æ—¥å¿—")
        with st.expander("ç‚¹å‡»æŸ¥çœ‹è¯¦ç»†å¤„ç†è®°å½•", expanded=True):
            for log in st.session_state['process_logs']:
                if "âŒ" in log: st.error(log)
                elif "âš ï¸" in log: st.warning(log)
                else: st.success(log)
    # --- å…¥åº“å‰ç¡®è®¤ ---
    if st.session_state.get('pending_import'):
        st.divider()
        st.subheader("ç¬¬ä¸‰æ­¥ï¼šç¡®è®¤å…¥åº“")
        stats = st.session_state['pending_import']['stats']
        success, fail, dup = stats.get("success", 0), stats.get("fail", 0), stats.get("duplicate", 0)
        col1, col2, col3 = st.columns(3)
        col1.metric("âœ… æˆåŠŸ", success, "æ¡å¯å…¥åº“")
        col2.metric("âŒ å¤±è´¥", fail, "æ¡")
        col3.metric("âš ï¸ é‡å¤", dup, "å·²è·³è¿‡")
        st.caption("æ–‡ä»¶å·²ä¿å­˜åˆ°æœ¬åœ°ã€‚ç‚¹å‡»ã€Œç¡®è®¤å…¥åº“ã€å°†æŠŠä¸Šè¿°æˆåŠŸé¡¹å†™å…¥æ•°æ®åº“ï¼›ç‚¹å‡»ã€Œå–æ¶ˆã€åˆ™ä»…ä¿ç•™æœ¬åœ°æ–‡ä»¶ï¼Œä¸å…¥åº“ã€‚")
        confirm_col, cancel_col, _ = st.columns([1, 1, 4])
        with confirm_col:
            if st.button("ç¡®è®¤å…¥åº“", type="primary", use_container_width=True, key="confirm_import"):
                core.commit_pending_to_db(st.session_state['pending_import']['pending_rows'])
                st.session_state['pending_import'] = None
                cached_get_library_stats.clear()
                st.session_state['show_success_celebration'] = {"toast": "å…¥åº“æˆåŠŸï¼å¯åœ¨ã€Œæ•°æ®åº“ç®¡ç†ã€æ£€ç´¢", "icon": "ğŸ—„ï¸"}
                st.rerun()
        with cancel_col:
            if st.button("å–æ¶ˆ", use_container_width=True, key="cancel_import"):
                st.session_state['pending_import'] = None
                st.rerun()
    # --- ä¸‹è½½åŒºï¼šå•æ–‡ä»¶ + å¤šæ–‡ä»¶ ZIP ---
    if st.session_state['process_done'] and st.session_state['processed_files']:
        st.divider()
        st.subheader("ğŸ“¥ ä¸‹è½½è½¬ç åçš„ SRT æ–‡ä»¶")
        files = st.session_state['processed_files']
        if st.session_state.get('pending_import'):
            st.caption("æ–‡ä»¶å·²ä¿å­˜åˆ°æœ¬åœ°ï¼›ç¡®è®¤å…¥åº“åå¯åœ¨ã€Œæ•°æ®åº“ç®¡ç†ã€ä¸­æ£€ç´¢ã€‚")
        else:
            st.caption("ä¸Šè¿°æ–‡ä»¶å·²ä¿å­˜åˆ°æœ¬åœ°å¹¶å†™å…¥æ•°æ®åº“ï¼Œå¯åœ¨ã€Œæ•°æ®åº“ç®¡ç†ã€ä¸­æ£€ç´¢ã€‚")
        if len(files) > 1:
            buf = io.BytesIO()
            with zipfile.ZipFile(buf, "w", zipfile.ZIP_DEFLATED) as zf:
                for f in files:
                    name = f.get("name", f.get("filename", getattr(f, "name", "unknown.srt")))
                    content = f.get("content", getattr(f, "content", ""))
                    if content is None:
                        content = ""
                    if isinstance(content, bytes):
                        content = content.decode("utf-8", errors="replace")
                    zf.writestr(name, content)
            buf.seek(0)
            st.download_button(
                label="ğŸ“¦ æ‰¹é‡ä¸‹è½½ (ZIP å‹ç¼©åŒ…)",
                data=buf.getvalue(),
                file_name="subtitles.zip",
                mime="application/zip",
                use_container_width=True,
                key="batch_zip_dl"
            )
        with st.container(border=True):
            for i, f in enumerate(files):
                name = f.get("name", f.get("filename", getattr(f, "name", "unknown.srt")))
                content = f.get("content", getattr(f, "content", None))
                if content is None and hasattr(f, "read"):
                    try:
                        f.seek(0)
                        content = f.read()
                        if isinstance(content, bytes):
                            content = content.decode("utf-8", errors="replace")
                    except Exception:
                        content = ""
                content = content or ""
                c_name, c_btn = st.columns([3, 1])
                c_name.write(f"ğŸ“„ {name}")
                if content:
                    c_btn.download_button(
                        label="ç‚¹å‡»ä¸‹è½½",
                        data=content,
                        file_name=name,
                        mime="text/plain",
                        key=f"dl_{i}_{name}_{i}",
                    )
                else:
                    c_btn.warning("æ–‡ä»¶ä¸ºç©º")

# ==========================================
# Tab 2ï¼šæ•°æ®åº“ç®¡ç†
# ==========================================
with tab2:
    st.header("2. æ ¸å¿ƒæ•°æ®åº“ (Memory Bank)")
    stats = cached_get_library_stats()
    with st.container(border=True):
        m1, m2, m3 = st.columns(3)
        m1.metric("ğŸ“š å·²æ”¶å½•ç”µå½±/å‰§é›†", f"{stats['movie_count']} éƒ¨")
        m2.metric("ğŸ’¬ å°è¯æ€»è¡Œæ•°", f"{stats['line_count']} è¡Œ")
        m3.metric("â±ï¸ æœ€åæ›´æ–°", stats['last_update'])
    st.divider()

    # --- åº“ç»´æŠ¤ï¼šæ‰«æä¸æ¸…ç† ---
    c1, c2 = st.columns([3, 1])
    with c1:
        st.info(f"å½“å‰ç›‘æ§çš„ç¡¬ç›˜è·¯å¾„: `{library_path}`")
    with c2:
        sync_btn = st.button("ğŸ”„ é‡æ–°æ‰«æç¡¬ç›˜ & é‡å»ºç´¢å¼•", use_container_width=True)
    if 'scan_result' not in st.session_state:
        st.session_state['scan_result'] = None
    if sync_btn:
        with st.status("æ­£åœ¨æ·±åº¦éå†ç¡¬ç›˜...", expanded=True) as status:
            try:
                st.write("ğŸ§  æ­£åœ¨åˆå§‹åŒ– AI æ¨¡å‹...")
                model_instance = load_embedding_model(selected_model)
            except Exception as e:
                status.update(label="âŒ æ¨¡å‹åŠ è½½å¤±è´¥", state="error")
                st.error(str(e))
                st.stop()
            for log, data in core.scan_library_path(library_path, model_instance, model_name=selected_model):
                if log == "DONE":
                    st.session_state['scan_result'] = data
                    status.update(label="âœ… æ‰«æå®Œæˆ", state="complete")
                    st.session_state['config']['embedding_model'] = selected_model
                    with open(CONFIG_FILE, 'w') as f:
                        json.dump(st.session_state['config'], f)
                else:
                    st.write(log)
            if st.session_state.get('scan_result') and st.session_state['scan_result'].get('success'):
                st.toast("ç´¢å¼•æ›´æ–°å®Œæ¯•ï¼", icon="ğŸ‰")
                time.sleep(1)
                st.rerun()
    if st.session_state.get('scan_result') and st.session_state['scan_result'].get('success'):
        res = st.session_state['scan_result']
        if res['new_added'] > 0:
            st.success(f"ğŸ‰ æˆåŠŸå…¥åº“ {res['new_added']} éƒ¨æ–°å½±ç‰‡ï¼")
        missing_count = len(res['missing_files'])
        if missing_count > 0:
            st.warning(f"âš ï¸ å‘ç°æ•°æ®åº“ä¸­æœ‰ {missing_count} ä¸ªæ–‡ä»¶åœ¨ç¡¬ç›˜ä¸Šæ‰¾ä¸åˆ°äº†ã€‚")
            with st.expander("æŸ¥çœ‹ä¸¢å¤±æ–‡ä»¶åˆ—è¡¨", expanded=False):
                for f in res['missing_files'][:10]:
                    st.code(f, language="text")
                if missing_count > 10:
                    st.caption(f"... ä»¥åŠå…¶ä»– {missing_count - 10} ä¸ªæ–‡ä»¶")
            col_del_text, col_del_btn = st.columns([3, 1])
            with col_del_text:
                st.write("è¿™äº›æ˜¯æ— æ•ˆçš„'å¹½çµè®°å½•'ï¼Œå»ºè®®æ¸…ç†ã€‚")
            with col_del_btn:
                if st.button("ğŸ—‘ï¸ ç¡®è®¤æ¸…ç†æ— æ•ˆè®°å½•", type="primary", use_container_width=True):
                    success, msg = core.delete_missing_records(res['missing_files'])
                    if success:
                        st.success(msg)
                        st.session_state['scan_result'] = None
                        time.sleep(1)
                        st.rerun()
                    else:
                        st.error(msg)
        elif res['new_added'] == 0:
            st.info("æ•°æ®åº“ä¸ç¡¬ç›˜å®Œå…¨åŒæ­¥ï¼Œæœªå‘ç°å˜åŠ¨ã€‚")
    st.divider()

    # --- æ™ºèƒ½æ£€ç´¢ï¼šå…³é”®è¯ / è¯­ä¹‰ ---
    st.subheader("ğŸ” æ™ºèƒ½æ£€ç´¢å°")
    query = st.text_input("è¯·è¾“å…¥æ£€ç´¢å†…å®¹", placeholder="è¾“å…¥å…³é”®è¯ï¼ˆå¦‚ï¼šé’±ï¼‰æˆ– æŠ½è±¡æ¦‚å¿µï¼ˆå¦‚ï¼šå‹æƒ…ã€é—æ†¾ï¼‰...", key="search_query")
    col_btn1, col_btn2, col_space = st.columns([1, 1, 4])
    with col_btn1:
        btn_keyword = st.button("ğŸ” å…³é”®è¯åŒ¹é…", use_container_width=True)
    with col_btn2:
        btn_semantic = st.button("ğŸ§  AI è¯­ä¹‰æœç´¢", use_container_width=True, type="primary")

    if btn_keyword and query:
        st.info(f"æ­£åœ¨è¿›è¡Œã€å…³é”®è¯ã€‘ç²¾ç¡®åŒ¹é…ï¼š'{query}' ...")
        results = core.search_db_keyword(query)
        st.write(f"æ‰¾åˆ° {len(results)} æ¡è®°å½•ï¼š")
        for res in results:
            with st.container(border=True):
                if res['season'] > 0 or res['episode'] > 0:
                    ep_info = f" `S{str(res['season']).zfill(2)}E{str(res['episode']).zfill(2)}`"
                else:
                    ep_info = ""
                st.markdown(f"**ğŸ¬ {res['movie']}**{ep_info} `[{res['time']}]`")
                st.text(res['content'])

    if btn_semantic and query:
        results = None
        with st.status("ğŸ§  AI æ­£åœ¨æ€è€ƒ...", expanded=True) as status:
            try:
                model_instance = load_embedding_model(selected_model)
                st.write("1. å‘é‡åŒ– (Embedding)...")
                results = core.search_db_semantic(query, model_instance)
                status.update(label="âœ… è¯­ä¹‰åŒ¹é…å®Œæˆï¼", state="complete", expanded=False)
            except Exception as e:
                status.update(label="âŒ æœç´¢å‡ºé”™", state="error")
                st.error(f"æœç´¢å¤±è´¥: {e}")
                st.stop()
        if results is not None:
            st.success(f"AI è”æƒ³åˆ°äº† {len(results)} æ¡ç›¸å…³å†…å®¹ï¼š")
            for res in results:
                with st.container(border=True):
                    ep = f" S{str(res['season']).zfill(2)}E{str(res['episode']).zfill(2)}" if (res.get('season') or 0) or (res.get('episode') or 0) else ""
                    st.markdown(f"**ğŸ¤– {res['movie']}**{ep} `[{res['time']}]`")
                    st.markdown(f"> *{res['content']}*")

# ==========================================
# Tab 3ï¼šAI æ··å‰ªå®éªŒå®¤
# ==========================================
with tab3:
    st.header("3. AI ç¼–å‰§æŒ‡æŒ¥å°")
    st.caption("åŸºäºè¯­ä¹‰åº“çš„æ™ºèƒ½å‰§æœ¬ç”Ÿæˆç³»ç»Ÿ")
    # --- çŠ¶æ€ä¸åˆ›ä½œåŒº ---
    llm_cfg = st.session_state.get('llm_config', {})
    has_key = bool(llm_cfg.get('api_key')) or llm_cfg.get('provider') == "Local (Ollama)"
    if has_key:
        st.success(f"ğŸŸ¢ AI å¼•æ“å°±ç»ª: {llm_cfg.get('provider')} ({llm_cfg.get('model_name')})")
    else:
        st.warning("âš ï¸ AI å¼•æ“æœªé…ç½®ï¼šè¯·ç‚¹å‡»å·¦ä¾§ä¾§è¾¹æ çš„ã€ŒğŸ”‘ LLM å¤§æ¨¡å‹é…ç½®ã€å¡«å…¥ API Keyã€‚")

    st.divider()
    c1, c2 = st.columns([3, 1])
    with c1:
        movie_list = core.get_all_movies()
        selected_movie = st.selectbox(
            "ğŸ“‚ æ ¸å¿ƒç´ ææ¥æº", 
            ["(å…¨åº“ç»¼åˆæœç´¢)"] + movie_list,
            help="é€‰æ‹©å…·ä½“çš„ç”µå½±ï¼ŒAI å°†ä¼˜å…ˆä½¿ç”¨è¯¥ç”µå½±çš„å°è¯ï¼›é€‰å…¨åº“åˆ™ä¼šè·¨ç”µå½±æ··å‰ªã€‚"
        )
    with c2:
        script_style = st.selectbox("ğŸ­ è„šæœ¬é£æ ¼", ["æƒ…æ„Ÿæ··å‰ª (é—æ†¾/æ²»æ„ˆ)", "ç‡ƒå‘è¸©ç‚¹ (åŠ¨ä½œ/åŠ±å¿—)", "é¢„å‘Šç‰‡ (æ‚¬ç–‘/æƒŠæ‚š)"])
    default_prompt = """ä¸»é¢˜ï¼šå…³äºã€æ—¶é—´ä¸é—æ†¾ã€‘
è¦æ±‚ï¼š
1. å¼€å¤´è¦æ…¢ï¼Œç”¨å‡ å¥å…³äºâ€œé”™è¿‡â€çš„å°è¯é“ºå«ã€‚
2. ä¸­æ®µèŠ‚å¥åŠ å¿«ï¼Œå±•ç¤ºäººç”Ÿä¸­çš„ä¸åŒé˜¶æ®µã€‚
3. ç»“å°¾è¦æœ‰ä¸€å¥æŒ¯è‹å‘è©çš„é‡‘å¥ï¼Œå‡åä¸»é¢˜ã€‚
4. ä¸éœ€è¦æ—ç™½ï¼Œå…¨éƒ¨ç”¨ç”µå½±åŸå£°å°è¯ã€‚"""
    prompt_text = st.text_area(
        "ğŸ“ å¯¼æ¼”æŒ‡ä»¤ (Prompt)", 
        value=default_prompt, 
        height=200,
        placeholder="åœ¨è¿™é‡Œå‘Šè¯‰ AI ä½ æƒ³å‰ªè¾‘ä»€ä¹ˆæ ·çš„è§†é¢‘..."
    )
    generate_btn = st.button("ğŸš€ ç”Ÿæˆæ··å‰ªè„šæœ¬", type="primary", use_container_width=True, disabled=not has_key)
    if generate_btn:
        with st.status("ğŸ¬ AI æ­£åœ¨åˆ›ä½œå‰§æœ¬...", expanded=True) as status:
            st.write("1. ğŸ§  ç†è§£å¯¼æ¼”æ„å›¾...")
            time.sleep(0.5)
            st.write(f"2. ğŸ” æ­£åœ¨æ£€ç´¢ '{selected_movie}' ç›¸å…³çš„è¯­ä¹‰å‘é‡...")
            time.sleep(1)
            st.write(f"3. âœï¸ æ­£åœ¨è¯·æ±‚ {llm_cfg.get('model_name')} ç”Ÿæˆåˆ†é•œ...")
            sys_prompt = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†é¢‘å‰ªè¾‘å¸ˆã€‚è¯·æŠŠç”¨æˆ·æä¾›çš„ç´ æå’Œè¦æ±‚ï¼Œå†™æˆMarkdownæ ¼å¼çš„å‰ªè¾‘è„šæœ¬è¡¨ã€‚"
            user_input = f"ç´ æèŒƒå›´ï¼š{selected_movie}\né£æ ¼ï¼š{script_style}\nè¯¦ç»†è¦æ±‚ï¼š{prompt_text}"
            try:
                response = core.call_deepseek_llm(
                    sys_prompt, 
                    user_input, 
                    llm_cfg['api_key']
                )
                status.update(label="âœ… åˆ›ä½œå®Œæˆï¼", state="complete", expanded=False)
                st.divider()
                st.subheader("ğŸ“„ æ··å‰ªè„šæœ¬")
                st.markdown(response)
                st.download_button(
                    label="ğŸ“¥ å¯¼å‡ºè„šæœ¬ (.md)",
                    data=response,
                    file_name=f"script_{int(time.time())}.md",
                    mime="text/markdown"
                )
            except Exception as e:
                status.update(label="âŒ ç”Ÿæˆå¤±è´¥", state="error")
                st.error(f"è°ƒç”¨ API å‡ºé”™: {e}")